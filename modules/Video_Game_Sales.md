## Videogame Sales


In this module, we'll work our way through an example Jupyter notebook that demonstrates how to use a built-in algorithm in SageMaker. More specifically, we'll use Amazon SageMaker's version of XGBoost, a popular and efficient open-source implementation of the gradient boosted trees algorithm. 

Gradient boosting is a supervised learning algorithm that attempts to predict a target variable by combining the estimates of a set of simpler, weaker models. XGBoost has done remarkably well in machine learning competitions because it robustly handles a wide variety of data types, relationships, and distributions. It often is a useful, go-to algorithm in working with structured data, such as data that might be found in relational databases and flat files. 

To proceed, follow these steps:

1. Be sure you have downloaded this GitHub repository as specified in **Preliminaries** before you start.  Next, in your notebook instance, click the **New** button on the right and select **Folder**.

2. Click the checkbox next to your new folder, click the **Rename** button above in the menu bar, and give the folder a name such as 'videogame-sales'.

3. Click the folder to enter it.

4. To upload the notebook for this module, click the **Upload** button on the right. Then in the file selection popup, select the file 'videogame-sales.ipynb' from the notebooks subdirectory in the folder on your computer where you downloaded this GitHub repository. **DO NOT USE THE DIFFERENT NOTEBOOK** 'videogame-sales-cli-console' (it uses the CLI and console with instructions in a different workshop module).  Click the blue **Upload** button that appears to the right of the notebook's file name.

5. You are now ready to begin the notebook:  click the notebook's file name to open it, then follow the directions in the notebook.


<p><strong>NOTE:  training the model for this example typically takes about 5 minutes or less.</strong></p>



